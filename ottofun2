#==============================================================================
#==============================================================================
# # OTTO PROGRAM
#==============================================================================
#==============================================================================

# =============================================================================
# Libraries
# =============================================================================

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn.neighbors import KNeighborsClassifier as knclass
from sklearn.linear_model import LogisticRegression as logit
from sklearn.naive_bayes import MultinomialNB as MNB
from sklearn.ensemble import ExtraTreesClassifier as extreesclass
from sklearn.svm import SVC


import rpy2.robjects as robjects
from rpy2.robjects import pandas2ri
import rpy2.robjects.packages as rpackages

pandas2ri.activate()
# =============================================================================
# Datasets
# =============================================================================

#Import data
data_csvn_train=pd.read_csv('train.csv', sep=',')

data_csv_train=pd.read_csv('train.csv', sep=',')
data_csv_train["target"]=data_csv_train["target"].map({"Class_{}".format(k):k-1 for k in range(1,10)})
data_csv_test=pd.read_csv('test.csv', sep=',')

data_target = data_csv_train["target"]

data_raw_all=data_csv_train.iloc[:,1:-1].append(data_csv_test.iloc[:,1:94])
data_raw_train=data_raw_all.iloc[0:len(data_csv_train),:]
data_raw_test=data_raw_all.iloc[len(data_csv_train):len(data_csv_train)+len(data_csv_test),:]

data_tsne_train=pd.read_csv('train_tsne.csv', sep=',',header=None)
data_tsne_test=pd.read_csv('test_tsne.csv', sep=',',header=None)


#DATA PREPROCESSING
#Pre-processing data into Log(x+1)
#data_log=dcopy(data_raw_train)
#data_log.iloc[:,1:-1]=np.log(data_raw_train.iloc[:,1:-1]+1)

data_log_all=np.log(data_raw_all+1)
data_log_train=data_log_all.iloc[0:len(data_raw_train),:]
data_log_test=data_log_all.iloc[len(data_raw_train):len(data_raw_train)+len(data_raw_test),:]

#preprocessing data into Scale(X)
#data_scale=dcopy(data_raw_train)
#data_scale.iloc[:,1:-1]=scale(data_raw_train.iloc[:,1:-1])
data_scale_all=pd.DataFrame(scale(data_raw_all))
data_scale_train=data_scale_all.iloc[0:len(data_raw_train),:]
data_scale_test=data_scale_all.iloc[len(data_raw_train):len(data_raw_train)+len(data_raw_test),:]

#preprocessing data into Scale(Log(X + 1))
#data_scale_log=dcopy(data_log)
#data_scale_log.iloc[:,1:-1]=scale(data_log.iloc[:,1:-1])

data_scalelog_all=pd.DataFrame(scale(data_log_all))
data_scalelog_train=data_scalelog_all.iloc[0:len(data_raw_train),:]
data_scalelog_test=data_scalelog_all.iloc[len(data_raw_train):len(data_raw_train)+len(data_raw_test),:]

#preprocessing data into sqrt(X + 3/8)
#data_sqrt=dcopy(data_raw_train)
#data_sqrt.iloc[:,1:-1]=np.sqrt(data_raw_train.iloc[:,1:-1]+3/8)
data_sqrt_all=np.sqrt(data_raw_all + 3/8)
data_sqrt_train=data_sqrt_all.iloc[0:len(data_raw_train),:]
data_sqrt_test=data_sqrt_all.iloc[len(data_raw_train):len(data_raw_train)+len(data_raw_test),:]

# Add feature int(X==0) called 'Num_0' to data
#data_featnum0=dcopy(data_raw_train)
#data_0 = np.count_nonzero(data_raw_train==0,axis=1) 
#data_featnum0.insert(data_featnum0.shape[1]-1,'Num_0',np.array(data_0,dtype=object))
data_0_all = np.count_nonzero(data_raw_all==0,axis=1) 
data_0_train = np.count_nonzero(data_raw_train==0,axis=1) 
data_0_test = np.count_nonzero(data_raw_test==0,axis=1) 

# Add feature log(x+1) to data_featnum0
#data_featnum0_featlog=dcopy(data_featnum0)
#for i in range(1,data_log.shape[1]-1):
#    data_featnum0_featlog.insert(data_featnum0_featlog.shape[1]-1,'Feat_{}_log'.format(i),np.array(data_log.iloc[:,i],dtype=object))


#Creation of the matrix where I store all the test and prediction datas
testsize = 15/data_raw_train.shape[0]
trainsize = 2/3

svc_trainsize=20000

matrix_train=pd.DataFrame()
matrix_test=pd.DataFrame()

#==============================================================================
# MODEL 24-33: KNN - Dataset: X
#==============================================================================
data = data_raw_train
data_test = data_raw_test
#from sklearn.neighbors import KNeighborsClassifier as knclass
#For loop that executes all KNN from k = 2 to k = 1024
for i in range(1,11):
    # Split data in train and test data
    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=i)
        
    #KNN with k from 2 to 1024
    knn = knclass(n_neighbors=2**i)
    knn.fit(X_train, Y_train)
    Ytrain_predict = knn.predict(data)
    Ytest_predict = knn.predict(data_test)
    
# Add the data to the matrix
    #matrix.insert(matrix.shape[1],'Y_test_knn{}'.format(2**i),np.array(Y_test,dtype=object))       
    matrix_train.insert(matrix_train.shape[1],'Y_predict_knn{}'.format(2**i),Ytrain_predict)
    matrix_test.insert(matrix_test.shape[1],'Y_predict_knn{}'.format(2**i),Ytest_predict)


matrix_train.to_csv('matrix_train_knn.csv')
matrix_test.to_csv('matrix_test_knn.csv')

#==============================================================================
# MODEL 4: KNEIGHBORS CLASSIFIER - Dataset: Scale(Log(x+1))
#==============================================================================
data = data_scalelog_train
data_test = data_scalelog_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=11)

#KNClassification
knn=knclass()
knn.fit(X_train,Y_train)

Ytrain_predict = knn.predict(data)
Ytest_predict = knn.predict(data_test)

Ytrain_predict.columns=['Y_train_knn_scale_log']
Ytest_predict.columns=['Y_test_knn_scale_log']

matrix_train.insert(matrix_train.shape[1],'Y_train_knn_scale_log',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_knn_scale_log',Ytest_predict)


pd.DataFrame(Ytrain_predict).to_csv('matrix_train_knn_scale_log.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_knn_scale_log.csv')

#==============================================================================
# MODEL 22: KNN on features X + int(X == 0)
#==============================================================================
data=data_raw_train.join(pd.DataFrame(data_0_train))
data_test=data_raw_test.join(pd.DataFrame(data_0_test))

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=12)

#KNClassification
knn=knclass()
knn.fit(X_train,Y_train)

Ytrain_predict = knn.predict(data)
Ytest_predict = knn.predict(data_test)

Ytrain_predict.columns=['Y_train_knn_x_0']
Ytest_predict.columns=['Y_test_knn_x_0']

matrix_train.insert(matrix_train.shape[1],'Y_train_knn_x_0',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_knn_x_0',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_knn_x_0.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_knn_x_0.csv')

# =============================================================================
# Model 23: KNN on features X + int(X == 0) + log(X + 1)
# =============================================================================

data=pd.concat([data_raw_train, pd.DataFrame(data_0_train),data_log_train], axis=1)
data_test=pd.concat([data_raw_test, pd.DataFrame(data_0_test),data_log_test], axis=1)


X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=13)

#KNClassification
knn=knclass()
knn.fit(X_train,Y_train)

Ytrain_predict = knn.predict(data)
Ytest_predict = knn.predict(data_test)

Ytrain_predict.columns=['Y_train_knn_x_0_log']
Ytest_predict.columns=['Y_test_knn_x_0_log']

matrix_train.insert(matrix_train.shape[1],'Y_train_knn_x_0_log',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_knn_x_0_log',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_knn_x_0_log.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_knn_x_0_log.csv')


#==============================================================================
# MODEL 2: LOG REGRESSION - Dataset: log(X+1))
#==============================================================================
data = data_scalelog_train
data_test = data_scalelog_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=14)

#Logistic Regression
logistic = logit()
logistic.fit(X_train,Y_train)

Ytrain_predict = logistic.predict(data)
Ytest_predict = logistic.predict(data_test)

Ytrain_predict.columns=['Y_train_logit']
Ytest_predict.columns=['Y_test_logit']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_logit',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_logit',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_logit_log.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_logit_log.csv')

#==============================================================================
# MODEL 3: EXTRA TREES CLASSIFIER - Dataset: log(X+1)
#==============================================================================
data = data_log_train
data_test = data_log_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=15)

#Extra Trees Classification
extratrees = extreesclass()
extratrees.fit(X_train,Y_train)

Ytrain_predict = extratrees.predict(data)
Ytest_predict = extratrees.predict(data_test)

Ytrain_predict.columns=['Y_train_extratrees']
Ytest_predict.columns=['Y_test_extratrees']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_extratrees',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_extratrees',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_extratrees_log.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_extratrees_log.csv')

# =============================================================================
# Model 7: Multinomial Naive Bayes - Dataset: Log(X+1)
# =============================================================================
data = data_log_train
data_test = data_log_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=16)

#Multinomial Naive Bayes Classification
multinb = MNB()
multinb.fit(X_train,Y_train)

Ytrain_predict = multinb.predict(data)
Ytest_predict = multinb.predict(data_test)

Ytrain_predict.columns=['Y_train_multinb']
Ytest_predict.columns=['Y_test_multinb']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_multinb',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_multinb',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_mnb_log.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_mnb_log.csv')


# =============================================================================
# Model 11: SVM(from scikit) - Dataset: scale(X)
# =============================================================================
data = data_scale_train
data_test = data_scale_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=svc_trainsize, random_state=17)

clf = SVC(gamma=2, C=1)
clf.fit(X_train, Y_train) 

Ytrain_predict = clf.predict(data)
Ytest_predict = clf.predict(data_test)

Ytrain_predict.columns=['Y_train_svc_scalex']
Ytest_predict.columns=['Y_test_svc_scalex']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_svc_scalex',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_svc_scalex',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_svc_scalex.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_svc_scalex.csv')

# =============================================================================
# Model 12: SVM(from scikit) - Dataset: X + T-SNE
# =============================================================================

data = pd.concat([pd.DataFrame(scale(data_raw_train)), pd.DataFrame(scale(data_tsne_train))], axis=1)
data_test = pd.concat([pd.DataFrame(scale(data_raw_test)), pd.DataFrame(scale(data_tsne_test))], axis=1)

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=svc_trainsize, random_state=18)


clf = SVC(gamma=2, C=1)
clf.fit(X_train, Y_train) 

Ytrain_predict = clf.predict(data)
Ytest_predict = clf.predict(data_test)

Ytrain_predict.columns=['Y_train_svc_x_tsne']
Ytest_predict.columns=['Y_test_svc_x_tsne']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_svc_x_tsne',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_svc_x_tsne',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_svc_x_tsne.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_svc_x_tsne.csv')

# =============================================================================
# Model 13: SVM(from scikit) - Dataset: Log(X + T-SNE)
# =============================================================================

data = pd.concat([pd.DataFrame(scale(np.log(1+data_raw_train))), pd.DataFrame(scale(np.log(1+np.abs(data_tsne_train))))], axis=1)
data_test = pd.concat([pd.DataFrame(scale(np.log(1+data_raw_test))), pd.DataFrame(scale(np.log(1+np.abs(data_tsne_test))))], axis=1)

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=svc_trainsize, random_state=19)

clf = SVC(gamma=2, C=1)
clf.fit(X_train, Y_train) 

Ytrain_predict = clf.predict(data)
Ytest_predict = clf.predict(data_test)

Ytrain_predict.columns=['Y_train_svc_log_x_tsne']
Ytest_predict.columns=['Y_test_svc_log_x_tsne']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_svc_log_x_tsne',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_svc_log_x_tsne',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_svc_log_x_tsne.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_svc_log_x_tsne.csv')

# =============================================================================
# Model 1: RandomForest(R) - Dataset: X
# =============================================================================
data = data_raw_train
data_test = data_raw_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=20)

dtest=pd.concat([X_train,Y_train], axis=1)
rtrain = pandas2ri.py2ri(dtest)
print(rtrain)
rtest = pandas2ri.py2ri(data_test)
print(rtest)

robjects.r('''
           f <- function(train) {
           
                    library(randomForest)
                    train1.rf <- randomForest(target ~ ., data=train, importance = TRUE, do.trace = 100)

            }
            ''')

utils = rpackages.importr('utils')
utils.chooseCRANmirror(ind=1) # select the first mirror in the list
#utils.install_packages('randomForest')

r_f = robjects.globalenv['f']
rf_model=(r_f(rtrain))


robjects.r('''
           g <- function(model,test) {

                    pred <- as.data.frame(predict(model, test))

            }
            ''')

r_g = robjects.globalenv['g']


Ytrain_predict = pandas2ri.ri2py(r_g(rf_model,pandas2ri.py2ri(data)))
Ytest_predict = pandas2ri.ri2py(r_g(rf_model,pandas2ri.py2ri(data_test)))

Ytrain_predict.columns=['Y_train_r_rf']
Ytest_predict.columns=['Y_test_r_rf']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_r_rf',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_r_rf',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_r_rf_x.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_r_rf_x.csv')

# =============================================================================
# Model 14-18: Xgboost(from R) - Dataset: X
# =============================================================================

#df = data
#indices = np.random.permutation(len(df))
#
#datatrain=df.iloc[indices[:5000],:]
#rdatatrain = pandas2ri.py2ri(dtest)
#
#datatest=df.iloc[indices[-15:],:]
#rdatatest = pandas2ri.py2ri(data_test)

data = data_raw_train
data_test = data_raw_test

X_train, X_test, Y_train, Y_test = train_test_split(data, data_csvn_train.iloc[:,94], test_size=testsize, train_size=trainsize, random_state=21)

dtest=pd.concat([X_train,Y_train], axis=1)
r_xgb1_datatrain = pandas2ri.py2ri(dtest)
print(r_xgb1_datatrain)
r_xgb1_datatest = pandas2ri.py2ri(data_test)
print(r_xgb1_datatest)

######################################
# import R's utility package
utils = rpackages.importr('utils')
utils.chooseCRANmirror(ind=1) # select the first mirror in the list
#utils.install_packages('xgboost')
#utils.install_packages('methods')
#utils.install_packages('data.table')
#utils.install_packages('magrittr')
#utils.install_packages('Ckmeans.1d.dp')
######################################



robjects.r('''
           f <- function(rdata,nround) {
            
            library(xgboost)
            library(methods)
            #install.packages("data.table", dependencies=TRUE)
            library(data.table)
            library(magrittr)
            library(Ckmeans.1d.dp)

            train<-data.table(rdata)
            
            # Delete ID column in training dataset
            #train[, id := NULL]
            
            # Save the name of the last column
            nameLastCol <- names(train)[ncol(train)]
            
            # Convert from classes to numbers
            y <- train[, nameLastCol, with = F][[1]] %>% gsub('Class_','',.) %>% {as.integer(.) -1}


            
            train[, nameLastCol:=NULL, with = F]
            
            trainMatrix <- train[,lapply(.SD,as.numeric)] %>% as.matrix
            
            numberOfClasses <- max(y) + 1
            param <- list("objective" = "multi:softprob",
                          "eval_metric" = "mlogloss",
                          "num_class" = numberOfClasses)
            
            
            bst = xgboost(param=param, data = trainMatrix, label = y, nrounds=nround)

            
            }
            ''')


r_f = robjects.globalenv['f']
rf_xgboostmodel=(r_f(r_xgb1_datatrain,50))
pandas2ri.ri2py(rf_xgboostmodel)

robjects.r('''
           g <- function(model,rdatatest,numberOfClasses) {
                    
                    library(xgboost)
                    library(methods)
                    library(data.table)
                    library(magrittr)
                    library(Ckmeans.1d.dp)

           
                    test<-data.table(rdatatest)
                    
                    # Delete ID column in training dataset
                    #test[, id := NULL]
                    
                    # Save the name of the last column
                    nameLastCol <- names(test)[ncol(test)]
                    
                    # Convert from classes to numbers
        
                    #test[, nameLastCol:=NULL, with = F]
                    
                    testMatrix <- test[,lapply(.SD,as.numeric)] %>% as.matrix


                    pred <- predict(model, testMatrix)
                    pred_ok<- matrix(pred,length(pred)/numberOfClasses, numberOfClasses,byrow = TRUE)

            }
            ''')

r_g = robjects.globalenv['g']

xgboostpredtrain=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data),9)))
xgboostpredtrain.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytrain_predict=xgboostpredtrain.idxmax(axis=1)

xgboostpredtest=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data_test),9)))
xgboostpredtest.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytest_predict=xgboostpredtest.idxmax(axis=1)

Ytrain_predict.columns=['Y_train_r_xgb1']
Ytest_predict.columns=['Y_test_r_xgb1']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_r_xgb1',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_r_xgb1',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_r_xgb1_x.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_r_xgb1_x.csv')

# =============================================================================
# Model 14-18: Xgboost(from R) - Dataset: X + Tsne
# =============================================================================

#df = data
#indices = np.random.permutation(len(df))
#
#datatrain=df.iloc[indices[:5000],:]
#rdatatrain = pandas2ri.py2ri(dtest)
#
#datatest=df.iloc[indices[-15:],:]
#rdatatest = pandas2ri.py2ri(data_test)

data = pd.concat([ pd.DataFrame(scale(data_raw_train)), pd.DataFrame(scale(data_tsne_train))], axis=1)
data_test = pd.concat([ pd.DataFrame(scale(data_raw_test)), pd.DataFrame(scale(data_tsne_test))], axis=1)

X_train, X_test, Y_train, Y_test = train_test_split(data, data_csvn_train.iloc[:,94], test_size=testsize, train_size=trainsize, random_state=22)

dtest=pd.concat([X_train,Y_train], axis=1)
r_xgb1_datatrain = pandas2ri.py2ri(dtest)
print(r_xgb1_datatrain)
r_xgb1_datatest = pandas2ri.py2ri(data_test)
print(r_xgb1_datatest)

######################################
# import R's utility package
utils = rpackages.importr('utils')
utils.chooseCRANmirror(ind=1) # select the first mirror in the list
#utils.install_packages('xgboost')
#utils.install_packages('methods')
#utils.install_packages('data.table')
#utils.install_packages('magrittr')
#utils.install_packages('Ckmeans.1d.dp')
######################################



robjects.r('''
           f <- function(rdata,nround) {
            
            library(xgboost)
            library(methods)
            #install.packages("data.table", dependencies=TRUE)
            library(data.table)
            library(magrittr)
            library(Ckmeans.1d.dp)

            train<-data.table(rdata)
            
            # Delete ID column in training dataset
            #train[, id := NULL]
            
            # Save the name of the last column
            nameLastCol <- names(train)[ncol(train)]
            
            # Convert from classes to numbers
            y <- train[, nameLastCol, with = F][[1]] %>% gsub('Class_','',.) %>% {as.integer(.) -1}


            
            train[, nameLastCol:=NULL, with = F]
            
            trainMatrix <- train[,lapply(.SD,as.numeric)] %>% as.matrix
            
            numberOfClasses <- max(y) + 1
            param <- list("objective" = "multi:softprob",
                          "eval_metric" = "mlogloss",
                          "num_class" = numberOfClasses)
            
            
            bst = xgboost(param=param, data = trainMatrix, label = y, nrounds=nround)

            
            }
            ''')


r_f = robjects.globalenv['f']
rf_xgboostmodel=(r_f(r_xgb1_datatrain,50))
pandas2ri.ri2py(rf_xgboostmodel)

robjects.r('''
           g <- function(model,rdatatest,numberOfClasses) {
                    
                    library(xgboost)
                    library(methods)
                    library(data.table)
                    library(magrittr)
                    library(Ckmeans.1d.dp)

           
                    test<-data.table(rdatatest)
                    
                    # Delete ID column in training dataset
                    #test[, id := NULL]
                    
                    # Save the name of the last column
                    nameLastCol <- names(test)[ncol(test)]
                    
                    # Convert from classes to numbers
        
                    #test[, nameLastCol:=NULL, with = F]
                    
                    testMatrix <- test[,lapply(.SD,as.numeric)] %>% as.matrix


                    pred <- predict(model, testMatrix)
                    pred_ok<- matrix(pred,length(pred)/numberOfClasses, numberOfClasses,byrow = TRUE)

            }
            ''')

r_g = robjects.globalenv['g']

xgboostpredtrain=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data),9)))
xgboostpredtrain.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytrain_predict=xgboostpredtrain.idxmax(axis=1)

xgboostpredtest=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data_test),9)))
xgboostpredtest.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytest_predict=xgboostpredtest.idxmax(axis=1)

Ytrain_predict.columns=['Y_train_r_xgb2_x_tsne']
Ytest_predict.columns=['Y_test_r_xgb2_x_tsne']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_r_xgb2_x_tsne',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_r_xgb2_x_tsne',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_r_xgb2_x_tsne.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_r_xgb2_x_tsne.csv')

# =============================================================================
# Model 14-18: Xgboost(from R) - Dataset: log(X + Tsne)
# =============================================================================

#df = data
#indices = np.random.permutation(len(df))
#
#datatrain=df.iloc[indices[:5000],:]
#rdatatrain = pandas2ri.py2ri(dtest)
#
#datatest=df.iloc[indices[-15:],:]
#rdatatest = pandas2ri.py2ri(data_test)

data = pd.concat([pd.DataFrame(scale(np.log(1+data_raw_train))), pd.DataFrame(scale(np.log(1+np.abs(data_tsne_train))))], axis=1)
data_test = pd.concat([pd.DataFrame(scale(np.log(1+data_raw_test))), pd.DataFrame(scale(np.log(1+np.abs(data_tsne_test))))], axis=1)

X_train, X_test, Y_train, Y_test = train_test_split(data, data_csvn_train.iloc[:,94], test_size=testsize, train_size=trainsize, random_state=23)

dtest=pd.concat([X_train,Y_train], axis=1)
r_xgb1_datatrain = pandas2ri.py2ri(dtest)
print(r_xgb1_datatrain)
r_xgb1_datatest = pandas2ri.py2ri(data_test)
print(r_xgb1_datatest)

######################################
# import R's utility package
utils = rpackages.importr('utils')
utils.chooseCRANmirror(ind=1) # select the first mirror in the list
#utils.install_packages('xgboost')
#utils.install_packages('methods')
#utils.install_packages('data.table')
#utils.install_packages('magrittr')
#utils.install_packages('Ckmeans.1d.dp')
######################################



robjects.r('''
           f <- function(rdata,nround) {
            
            library(xgboost)
            library(methods)
            #install.packages("data.table", dependencies=TRUE)
            library(data.table)
            library(magrittr)
            library(Ckmeans.1d.dp)

            train<-data.table(rdata)
            
            # Delete ID column in training dataset
            #train[, id := NULL]
            
            # Save the name of the last column
            nameLastCol <- names(train)[ncol(train)]
            
            # Convert from classes to numbers
            y <- train[, nameLastCol, with = F][[1]] %>% gsub('Class_','',.) %>% {as.integer(.) -1}


            
            train[, nameLastCol:=NULL, with = F]
            
            trainMatrix <- train[,lapply(.SD,as.numeric)] %>% as.matrix
            
            numberOfClasses <- max(y) + 1
            param <- list("objective" = "multi:softprob",
                          "eval_metric" = "mlogloss",
                          "num_class" = numberOfClasses)
            
            
            bst = xgboost(param=param, data = trainMatrix, label = y, nrounds=nround)

            
            }
            ''')


r_f = robjects.globalenv['f']
rf_xgboostmodel=(r_f(r_xgb1_datatrain,50))
pandas2ri.ri2py(rf_xgboostmodel)

robjects.r('''
           g <- function(model,rdatatest,numberOfClasses) {
                    
                    library(xgboost)
                    library(methods)
                    library(data.table)
                    library(magrittr)
                    library(Ckmeans.1d.dp)

           
                    test<-data.table(rdatatest)
                    
                    # Delete ID column in training dataset
                    #test[, id := NULL]
                    
                    # Save the name of the last column
                    nameLastCol <- names(test)[ncol(test)]
                    
                    # Convert from classes to numbers
        
                    #test[, nameLastCol:=NULL, with = F]
                    
                    testMatrix <- test[,lapply(.SD,as.numeric)] %>% as.matrix


                    pred <- predict(model, testMatrix)
                    pred_ok<- matrix(pred,length(pred)/numberOfClasses, numberOfClasses,byrow = TRUE)

            }
            ''')

r_g = robjects.globalenv['g']

xgboostpredtrain=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data),9)))
xgboostpredtrain.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytrain_predict=xgboostpredtrain.idxmax(axis=1)

xgboostpredtest=pd.DataFrame(pandas2ri.ri2py(r_g(rf_xgboostmodel,pandas2ri.py2ri(data_test),9)))
xgboostpredtest.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']
Ytest_predict=xgboostpredtest.idxmax(axis=1)

Ytrain_predict.columns=['Y_train_r_xgb3_log_x_tsne']
Ytest_predict.columns=['Y_test_r_xgb3_log_x_tsne']

# Add the data to the matrix
matrix_train.insert(matrix_train.shape[1],'Y_train_r_xgb3_log_x_tsne',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_r_xgb3_log_x_tsne',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_r_xgb3_log_x_tsne.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_r_xgb3_log_x_tsne.csv')

# =============================================================================
# Model 8: Tensorflow NN. Bag of 2 runs. First with Dataset: Scale( Log(X+1) ) and second with Dataset: Scale( X )
# =============================================================================
'''reference at https://www.kaggle.com/xenocide/tensorflow-neural-network-tutorial-with-iris-data'''

data = data_raw_train
columns = data.columns

data = [data_scalelog_train,data_scale_train]
data_test = [data_scalelog_test,data_scale_test]

dataname=["data_scale","data_scalelog"]
#Create the matrix where I store the data
#predictions = pd.DataFrame()
predictions_proba_train = pd.DataFrame()
predictions_proba_test = pd.DataFrame()

#Repeat for both datasets
for i in [0,1]:
    X_train, X_test, Y_train, Y_test = train_test_split(data[i], data_target, test_size=testsize, train_size=trainsize, random_state=24+i)
    #X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=24+i)

    #columns = data[i].columns
    #columns = data.columns

    feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]
    
    def input_fn(df,labels):
        feature_cols = {k:tf.constant(df[k].values,shape = [df[k].size,1]) for k in columns}
        label = tf.constant(labels.values, shape = [labels.size,1])
        return feature_cols,label
    
    X_train.columns=columns #WTF!
    data[i].columns=columns
    data_test[i].columns=columns
    
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20],n_classes = 9)
    classifier.fit(input_fn=lambda: input_fn(X_train,Y_train),steps = 1000)

#    Check precision of the fitting
    
#    #ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)
#    #print(ev)

    def input_predict(df):
        feature_cols = {k:tf.constant(df[k].values,shape = [df[k].size,1]) for k in columns}
        return feature_cols

    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data[i]))
    predictions_proba_train.insert(predictions_proba_train.shape[1],dataname[i],list(pred_proba_train))
    
    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data_test[i]))
    predictions_proba_test.insert(predictions_proba_test.shape[1],dataname[i],list(pred_proba_test))
#    pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))
#    predictions.insert(predictions.shape[1],dataname[i],list(pred))
    
#Bagging
    
def bag_proba(df):
    bag_class = list()
    for row in range(df.shape[0]):
        mean_prob = np.mean(df.values[row,:])
        for i, j in enumerate(mean_prob):
            if j == max(mean_prob):
                bag_class.append(i)
    return pd.DataFrame(bag_class)
            
Ytrain_predict = bag_proba(predictions_proba_train)
Ytest_predict = bag_proba(predictions_proba_test)
                    
Ytrain_predict.columns=['Y_train_tfNN-2x']
Ytest_predict.columns=['Y_test_tfNN-2x']

matrix_train.insert(matrix_train.shape[1],'Y_train_tfNN-2x',Ytrain_predict)
matrix_test.insert(matrix_test.shape[1],'Y_test_tfNN-2x',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_tfNN-2x.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_tfNN-2x.csv')
    
# =============================================================================
# Model 9: Tensorflow NN. Bag of 6 runs. Dataset: Scale( Log(X+1) )            
# =============================================================================
data = data_scalelog_train
data_test = data_scalelog_test

#predictions = pd.DataFrame()
predictions_proba_train = pd.DataFrame()
predictions_proba_test = pd.DataFrame()

#columns = data.columns
feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]

#Run 6 times
nruns=6
run=0
while run < nruns:
    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=26+run)
    
    X_train.columns=columns #WTF!    
    
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20],n_classes = 9)
    classifier.fit(input_fn=lambda: input_fn(X_train,Y_train),steps = 1000)
    

    #    Check precision of the fitting
    #    #ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)
    #    #print(ev)
    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
    
    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data_test))
    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
    
#    pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))
#    predictions.insert(predictions.shape[1],"run{}".format(run+1),list(pred))
    run+=1

#Bagging
Ytrain_predict = bag_proba(predictions_proba_train)
Ytest_predict = bag_proba(predictions_proba_test)
        
Ytrain_predict.columns=['Y_train_tfNN-6x']
Ytest_predict.columns=['Y_test_tfNN-6x']
            
matrix_train.insert(matrix_train.shape[1],'Y_train_tfNN-6x',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_tfNN-6x',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_tfNN-6x.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_tfNN-6x.csv')  
  
# =============================================================================
# Model 6: Tensorflow NN. Bag of 10 runs. Dataset: sqrt( X + 3/8)
# =============================================================================
data = data_sqrt_train
data_test = data_sqrt_test

#predictions = pd.DataFrame()
predictions_proba_train = pd.DataFrame()
predictions_proba_test = pd.DataFrame()

#columns = data.columns
feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]

#Run 10 times
nruns=10
run=0
while run < nruns:
    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=32+run)
    
    X_train.columns=columns #WTF!      
    
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20],n_classes = 9)
    classifier.fit(input_fn=lambda: input_fn(X_train,Y_train),steps = 1000)
    
    #    Check precision of the fitting
    #    #ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)
    #    #print(ev)
    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
    
    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data_test))
    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
    
#    pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))
#    predictions.insert(predictions.shape[1],"run{}".format(run+1),list(pred))
    run+=1

#Bagging
Ytrain_predict = bag_proba(predictions_proba_train)
Ytest_predict = bag_proba(predictions_proba_test)

Ytrain_predict.columns=['Y_train_tfNN-10x']
Ytest_predict.columns=['Y_test_tfNN-10x']        

matrix_train.insert(matrix_train.shape[1],'Y_train_tfNN-10x',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_tfNN-10x',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_tfNN-10x.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_tfNN-10x.csv')  

# =============================================================================
# Model 19: Tensorflow NN(GPU). 2-Layer. Bag of 120 NN runs with different number of epochs.
# =============================================================================
data = data_raw_train
data_test = data_raw_test

#predictions = pd.DataFrame()
predictions_proba_train = pd.DataFrame()
predictions_proba_test = pd.DataFrame()
predictions_train = pd.DataFrame()
predictions_test = pd.DataFrame()

#columns = data.columns
feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]

#Run 120 times
nruns=120
run=0

while run < nruns:
    print("----------ITERATION N. {} - 2lay----------".format(run+1))
    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=42+run)
    X_train.columns=columns #WTF!          
    
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20,10],n_classes = 9)
    classifier.fit(input_fn=lambda: input_fn(X_train,Y_train),steps = 1000)
    
    #    Check precision of the fitting
    #    #ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)
    #    #print(ev)
    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
    
    #da giu' di sotto copio queste
    pred_train = classifier.predict_classes(input_fn=lambda: input_predict(data))
    predictions_train.insert(predictions_train.shape[1],"run{}".format(run+1),list(pred_train))
    #fino a qui
    
    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data_test))
    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
    
    #da giu' di sotto copio queste
    pred_test = classifier.predict_classes(input_fn=lambda: input_predict(data))
    predictions_test.insert(predictions_test.shape[1],"run{}".format(run+1),list(pred_test))
    #fino a qui
    
#    pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))
#    predictions.insert(predictions.shape[1],"run{}".format(run+1),list(pred))
    
    run+=1

##NON CAPISCO DA QUI
#    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
#    pred_train = classifier.predict_classes(input_fn=lambda: input_predict(data))
#    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
#    predictions_train.insert(predictions_train.shape[1],"run{}".format(run+1),list(pred_train))
#    
#    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data))
#    pred_test = classifier.predict_classes(input_fn=lambda: input_predict(data))
#    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
#    predictions_test.insert(predictions_test.shape[1],"run{}".format(run+1),list(pred_test))
##A QUI... commento

#Bagging
def bag_num(df):
    bag_class = list()
    class_mode = df.mode(axis=1).iloc[:,0]
    for row in range(class_mode.shape[0]):
        class_mode_int = int(class_mode.iloc[row])
        bag_class.append(class_mode_int)
    return pd.DataFrame(bag_class)    
    
#Ytrain_predict = bag_num(predictions_train)
#Ytest_predict = bag_num(predictions_test)

Ytrain_predict = bag_proba(predictions_proba_train)
Ytest_predict = bag_proba(predictions_proba_test)

Ytrain_predict.columns=['Y_train_tfNN-120x-2lay']
Ytest_predict.columns=['Y_test_tfNN-120x-2lay'] 
                    
matrix_train.insert(matrix_train.shape[1],'Y_train_tfNN-120x-2lay',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_tfNN-120x-2lay',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_tfNN-120x-2lay.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_tfNN-120x-2lay.csv')  

# =============================================================================
# Model 20: Tensorflow NN(GPU). 3-Layer. Bag of 120 NN runs with different number of epochs.
# =============================================================================
data = data_raw_train
data_test = data_raw_test

#predictions = pd.DataFrame()
predictions_proba_train = pd.DataFrame()
predictions_proba_test = pd.DataFrame()
predictions_train = pd.DataFrame()
predictions_test = pd.DataFrame()

columns = data.columns
feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]

#Run 120 times
nruns=120
run=0
while run < nruns:
    print("----------ITERATION N. {} - 3lay----------".format(run+1))
    X_train, X_test, Y_train, Y_test = train_test_split(data, data_target, test_size=testsize, train_size=trainsize, random_state=162+run)
    X_train.columns=columns 
    
    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20,10,10],n_classes = 9)
    classifier.fit(input_fn=lambda: input_fn(X_train,Y_train),steps = 1000)
    
    #    Check precision of the fitting
    #    #ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)
    #    #print(ev)
    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
    pred_train = classifier.predict_classes(input_fn=lambda: input_predict(data))
    predictions_train.insert(predictions_train.shape[1],"run{}".format(run+1),list(pred_train))
    
    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data_test))
    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
    pred_test = classifier.predict_classes(input_fn=lambda: input_predict(data))
    predictions_test.insert(predictions_test.shape[1],"run{}".format(run+1),list(pred_test))
    
#    pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))
#    predictions.insert(predictions.shape[1],"run{}".format(run+1),list(pred))
    run+=1

#    pred_proba_train = classifier.predict_proba(input_fn=lambda: input_predict(data))
#    pred_train = classifier.predict_classes(input_fn=lambda: input_predict(data))
#    predictions_proba_train.insert(predictions_proba_train.shape[1],"run{}".format(run+1),list(pred_proba_train))
#    predictions_train.insert(predictions_train.shape[1],"run{}".format(run+1),list(pred_train))
#    
#    pred_proba_test = classifier.predict_proba(input_fn=lambda: input_predict(data))
#    pred_test = classifier.predict_classes(input_fn=lambda: input_predict(data))
#    predictions_proba_test.insert(predictions_proba_test.shape[1],"run{}".format(run+1),list(pred_proba_test))
#    predictions_test.insert(predictions_test.shape[1],"run{}".format(run+1),list(pred_test))


#Bagging

#Ytrain_predict = bag_num(predictions_train)
#Ytest_predict = bag_num(predictions_test)

Ytrain_predict = bag_proba(predictions_proba_train)
Ytest_predict = bag_proba(predictions_proba_test)

Ytrain_predict.columns=['Y_train_tfNN-120x-3lay']
Ytest_predict.columns=['Y_test_tfNN-120x-3lay']  
                    
matrix_train.insert(matrix_train.shape[1],'Y_train_tfNN-120x-3lay',Ytrain_predict)       
matrix_test.insert(matrix_test.shape[1],'Y_test_tfNN-120x-3lay',Ytest_predict)

pd.DataFrame(Ytrain_predict).to_csv('matrix_train_tfNN-120x-3lay.csv')
pd.DataFrame(Ytest_predict).to_csv('matrix_test_tfNN-120x-3lay.csv') 
